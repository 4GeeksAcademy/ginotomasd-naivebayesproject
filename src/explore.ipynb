{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your code here\n",
                "\n",
                "import pandas as pd\n",
                "\n",
                "# Step 1: Load the dataset\n",
                "url = \"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\"\n",
                "df = pd.read_csv(url)\n",
                "\n",
                "print(\"Dataset shape:\", df.shape)\n",
                "print(df.head())\n",
                "\n",
                "# Step 2: Preprocessing\n",
                "# Remove the app name column as it is not relevant for sentiment analysis\n",
                "df = df.drop('package_name', axis=1)\n",
                "\n",
                "# Standardize the review text: remove extra spaces and convert to lowercase\n",
                "df['review'] = df['review'].str.strip().str.lower()\n",
                "\n",
                "# Define predictor and target variables\n",
                "X = df['review']\n",
                "y = df['polarity']\n",
                "\n",
                "# Split the dataset into training and test sets\n",
                "from sklearn.model_selection import train_test_split\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# Transform text data into numeric features using Bag-of-Words\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "vec_model = CountVectorizer(stop_words=\"english\")\n",
                "X_train_vec = vec_model.fit_transform(X_train).toarray()\n",
                "X_test_vec = vec_model.transform(X_test).toarray()\n",
                "\n",
                "# Step 3: Train and evaluate Naive Bayes models\n",
                "\n",
                "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "# MultinomialNB (recommended for text data)\n",
                "nb_m = MultinomialNB()\n",
                "nb_m.fit(X_train_vec, y_train)\n",
                "y_pred_m = nb_m.predict(X_test_vec)\n",
                "print(\"MultinomialNB accuracy:\", accuracy_score(y_test, y_pred_m))\n",
                "print(classification_report(y_test, y_pred_m))\n",
                "\n",
                "# BernoulliNB (good for binary word occurrence features)\n",
                "nb_b = BernoulliNB()\n",
                "nb_b.fit(X_train_vec, y_train)\n",
                "y_pred_b = nb_b.predict(X_test_vec)\n",
                "print(\"BernoulliNB accuracy:\", accuracy_score(y_test, y_pred_b))\n",
                "print(classification_report(y_test, y_pred_b))\n",
                "\n",
                "# GaussianNB (not ideal for text, but included for comparison)\n",
                "nb_g = GaussianNB()\n",
                "nb_g.fit(X_train_vec, y_train)\n",
                "y_pred_g = nb_g.predict(X_test_vec)\n",
                "print(\"GaussianNB accuracy:\", accuracy_score(y_test, y_pred_g))\n",
                "print(classification_report(y_test, y_pred_g))\n",
                "\n",
                "# Step 4: Random Forest as an alternative\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
                "rf.fit(X_train_vec, y_train)\n",
                "y_pred_rf = rf.predict(X_test_vec)\n",
                "print(\"Random Forest accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
                "print(classification_report(y_test, y_pred_rf))\n",
                "\n",
                "# Step 5: Save the models\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "os.makedirs('models', exist_ok=True)\n",
                "joblib.dump(nb_m, 'models/best_naive_bayes.pkl')\n",
                "joblib.dump(rf, 'models/random_forest_vec.pkl')\n",
                "print(\"Models saved to 'models/' directory.\")\n",
                "\n",
                "# Step 6: Try another model: Logistic Regression\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "lr = LogisticRegression(max_iter=1000)\n",
                "lr.fit(X_train_vec, y_train)\n",
                "y_pred_lr = lr.predict(X_test_vec)\n",
                "print(\"Logistic Regression accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
                "print(classification_report(y_test, y_pred_lr))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
